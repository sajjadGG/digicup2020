{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'rate'\n",
    "mypath = 'data/vision/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "\"pink\" : 1,\n",
    "\"purple\":2,\n",
    "\"yellow\" :3,\n",
    "\"orange\":4,\n",
    "\"white\":5,\n",
    "\"silver\":6,\n",
    "\"grey\":7,\n",
    "\"black\":8,\n",
    "\"red\":9,\n",
    "\"brown\":10,\n",
    "\"green\":11,\n",
    "\"blue\":12\n",
    "}\n",
    "input_dim = 224\n",
    "n_channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join , isdir\n",
    "onlyfolders = [f for f in listdir(mypath) if isdir(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = onlyfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('data/vision/train/black/105184860.jpg')\n",
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in onlyfolders:\n",
    "    path = \"{}/{}/\".format(mypath , d)\n",
    "    onlyfiles = [join(path, f) for f in listdir(path) if isfile(join(path, f))]\n",
    "    for f in onlyfiles:\n",
    "        images.append(np.array(Image.open(f)))\n",
    "        labels.append(colors[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=np.rollaxis(X, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6239, 224, 224, 3), (6239,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6239, 150528)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i , ix in enumerate(images):\n",
    "    images[i] = ix.flatten()\n",
    "Xf = np.array(images)\n",
    "Xf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.flatten>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lion\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(Xf, np.array(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(8,), random_state=1 , verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6239, 12)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(Xf).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7300849495111396"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xf , y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LeNET(nn.Module):\n",
    "    def __init__(self , input_dim):\n",
    "        super(LeNET,self).__init__()\n",
    "        self.conv_model = nn.Sequential(nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5),   # (N,3,224,224) --> (N,6,220,220) \n",
    "                                        nn.Tanh(),                                               # TanH --> Activation Function\n",
    "                                        nn.AvgPool2d(kernel_size=2,stride=2),                    # (N,6,220,220) --> (N,6,110,110)\n",
    "                                        nn.Conv2d(6,16,5),nn.Tanh(),                             # (N,6,110,110) --> (N,16,106,106)\n",
    "                                        nn.AvgPool2d(2,stride=2),                                # (N,16,106,106) --> (N,16,52,52)\n",
    "                                        nn.Conv2d(16,32,5),nn.Tanh(), \n",
    "                                        nn.AvgPool2d(2,stride=2))\n",
    "\n",
    "        #Dense Layer\n",
    "        self.dense_layer = nn.Sequential(nn.Linear(in_features=18432,out_features=120),           #16*5*5 = 400 as input\n",
    "                                         nn.Tanh(),\n",
    "                                         nn.Linear(120,84),\n",
    "                                         nn.Tanh(),\n",
    "                                     nn.Linear(84,13))\n",
    "    def forward(self,x):\n",
    "        y = self.conv_model(x)\n",
    "        #flatten the result from Conv model\n",
    "        y = torch.flatten(y,1) # 1 --> dimension (N,16,5,5)\n",
    "        y = self.dense_layer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNET(input_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(X ,y ,net , batch_size):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(0,len(X)//batch_size):\n",
    "        images = torch.from_numpy(X[i*batch_size:(i+1)*batch_size]).cuda()\n",
    "        lables = torch.from_numpy(y[i*batch_size:(i+1)*batch_size]).cuda()\n",
    "        out = net(images)\n",
    "        max_val, preds = torch.max(out,dim=1)\n",
    "        #accuracy = (correctly predicted class / total testing class) Ã— 100%\n",
    "        total += lables.shape[0]                   # class value \n",
    "        correct += (preds == lables).sum().item()  # to summ correct in the batch then sum all of it\n",
    "    accuracy = (100 * correct)/total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "out = net(torch.from_numpy(X[:10]))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(out , torch.tensor([1 for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(out , torch.tensor(torch.from_numpy(y_train[:10]),dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# defining optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(torch.rand(image_data.shape).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "\n",
    "for j in range(epoch):\n",
    "\n",
    "    for i in range(0,len(X_train)//batch_size):\n",
    "        image_data = torch.from_numpy(X_train[i*batch_size:(i+1)*batch_size]).cuda()\n",
    "        \n",
    "        labels = torch.tensor(torch.from_numpy(y_train[i*batch_size:(i+1)*batch_size]) ,dtype=torch.long).cuda()\n",
    "        #print(i,image_data.shape)\n",
    "        \n",
    "#         print(image_data)\n",
    "        out = net(image_data) #image_data --> input data\n",
    "        loss = loss_func(out , labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_acc = model_eval(X_train,y_train , net , batch_size) \n",
    "    test_acc  = model_eval(X_test,y_test , net , batch_size)\n",
    "\n",
    "    print(\"Epoch :\",j,\" train acc : \"  ,train_acc , \"test acc : \" , test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = model_eval(X_train,y_train , net , 32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypathtest = 'data/vision/test/'\n",
    "imagestest =[]\n",
    "ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onlyfiles = [f for f in listdir(mypathtest) if isfile(join(mypathtest, f))]\n",
    "for f in onlyfiles:\n",
    "    imagestest.append(np.array(Image.open(join(mypathtest, f))))\n",
    "    ids.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imagestest)):\n",
    "    imagestest[i] = imagestest[i].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2673, 150528)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtf = np.array(imagestest)\n",
    "Xtf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.array(imagestest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2673, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-75fc214beeef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame.from_dict({'file_name' : ids , 'color_id' : pred})\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.sort_values('file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv('data/vision/ans1.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization, Lambda, Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17094746867180398020\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4510031374925429415\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4305363208865209104\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_net(num_classes):\n",
    "    # placeholder for input image\n",
    "    input_image = Input(shape=(input_dim,input_dim,3))\n",
    "    # ============================================= TOP BRANCH ===================================================\n",
    "    # first top convolution layer\n",
    "    top_conv1 = Convolution2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(input_dim,input_dim,3),activation='relu')(input_image)\n",
    "    top_conv1 = BatchNormalization()(top_conv1)\n",
    "    top_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_conv1)\n",
    "\n",
    "    # second top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(top_conv1)\n",
    "    top_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(top_conv1)\n",
    "\n",
    "    top_top_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv2)\n",
    "    top_top_conv2 = BatchNormalization()(top_top_conv2)\n",
    "    top_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv2)\n",
    "\n",
    "    top_bot_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv2)\n",
    "    top_bot_conv2 = BatchNormalization()(top_bot_conv2)\n",
    "    top_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv2)\n",
    "\n",
    "    # third top convolution layer\n",
    "    # concat 2 feature map\n",
    "    top_conv3 = Concatenate()([top_top_conv2,top_bot_conv2])\n",
    "    top_conv3 = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_conv3)\n",
    "\n",
    "    # fourth top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(top_conv3)\n",
    "    top_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(top_conv3)\n",
    "\n",
    "    top_top_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_bot_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "\n",
    "    # fifth top convolution layer\n",
    "    top_top_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv5) \n",
    "\n",
    "    top_bot_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "    top_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv5)\n",
    "\n",
    "    # ============================================= TOP BOTTOM ===================================================\n",
    "    # first bottom convolution layer\n",
    "    bottom_conv1 = Convolution2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(227,227,3),activation='relu')(input_image)\n",
    "    bottom_conv1 = BatchNormalization()(bottom_conv1)\n",
    "    bottom_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_conv1)\n",
    "\n",
    "    # second bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(bottom_conv1)\n",
    "    bottom_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(bottom_conv1)\n",
    "\n",
    "    bottom_top_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv2)\n",
    "    bottom_top_conv2 = BatchNormalization()(bottom_top_conv2)\n",
    "    bottom_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv2)\n",
    "\n",
    "    bottom_bot_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = BatchNormalization()(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv2)\n",
    "\n",
    "    # third bottom convolution layer\n",
    "    # concat 2 feature map\n",
    "    bottom_conv3 = Concatenate()([bottom_top_conv2,bottom_bot_conv2])\n",
    "    bottom_conv3 = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_conv3)\n",
    "\n",
    "    # fourth bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(bottom_conv3)\n",
    "    bottom_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(bottom_conv3)\n",
    "\n",
    "    bottom_top_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_bot_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "\n",
    "    # fifth bottom convolution layer\n",
    "    bottom_top_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv5) \n",
    "\n",
    "    bottom_bot_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "    bottom_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv5)\n",
    "\n",
    "    # ======================================== CONCATENATE TOP AND BOTTOM BRANCH =================================\n",
    "    conv_output = Concatenate()([top_top_conv5,top_bot_conv5,bottom_top_conv5,bottom_bot_conv5])\n",
    "\n",
    "    # Flatten\n",
    "    flatten = Flatten()(conv_output)\n",
    "\n",
    "    # Fully-connected layer\n",
    "    FC_1 = Dense(units=4096, activation='relu')(flatten)\n",
    "    FC_1 = Dropout(0.6)(FC_1)\n",
    "    FC_2 = Dense(units=4096, activation='relu')(FC_1)\n",
    "    FC_2 = Dropout(0.6)(FC_2)\n",
    "    output = Dense(units=num_classes, activation='softmax')(FC_2)\n",
    "    \n",
    "    model = Model(inputs=input_image,outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # sgd = SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6239, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "categorical_labels = to_categorical(labels, num_classes=13)\n",
    "categorical_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise model\n",
    "num_classes = len(colors)+1\n",
    "model = color_net(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 54, 54, 48)   17472       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 54, 54, 48)   17472       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 54, 54, 48)   192         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 48)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 26, 26, 48)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 26, 26, 48)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 26, 26, 24)   0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 26, 26, 24)   0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 26, 26, 24)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 26, 26, 24)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 26, 26, 64)   13888       lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 26, 26, 64)   13888       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 26, 26, 64)   13888       lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 26, 26, 64)   13888       lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 26, 26, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 26, 26, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 26, 26, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 26, 26, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 12, 12, 128)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 128)  0           max_pooling2d_6[0][0]            \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 12, 12, 192)  221376      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 12, 12, 192)  221376      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 12, 12, 96)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 12, 12, 96)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 12, 12, 96)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 12, 12, 96)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 12, 96)   83040       lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 12, 12, 96)   83040       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 12, 12, 96)   83040       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 12, 12, 96)   83040       lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 12, 12, 64)   55360       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 12, 12, 64)   55360       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 12, 12, 64)   55360       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 12, 12, 64)   55360       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 64)     0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 64)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 5, 5, 64)     0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 5, 5, 64)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 256)    0           max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6400)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         26218496    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         16781312    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 13)           53261       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,141,325\n",
      "Trainable params: 44,140,621\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('color_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(      \n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "advtx , advty = [] , []\n",
    "hard_to_guess = [1,5,6,7,10]\n",
    "n=500\n",
    "for ha in hard_to_guess:\n",
    "    jc=0\n",
    "    for i , la in enumerate(labels):\n",
    "        if(la ==ha):\n",
    "            advtx.append(images[i])\n",
    "            advty.append(la)\n",
    "            jc+=1\n",
    "        if(jc>=n):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(advty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "advX = np.array(advtx)\n",
    "advY = np.array(advty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-8, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lion\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Lion\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Lion\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:739: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/24 [==============================] - 62s 2s/step - loss: 0.1776 - accuracy: 0.9377\n",
      "Epoch 2/10\n",
      "25/24 [==============================] - 62s 2s/step - loss: 0.1775 - accuracy: 0.9368\n",
      "Epoch 3/10\n",
      "25/24 [==============================] - 62s 2s/step - loss: 0.1732 - accuracy: 0.9388\n",
      "Epoch 4/10\n",
      "25/24 [==============================] - 62s 2s/step - loss: 0.1787 - accuracy: 0.9397\n",
      "Epoch 5/10\n",
      "25/24 [==============================] - 64s 3s/step - loss: 0.1754 - accuracy: 0.9399\n",
      "Epoch 6/10\n",
      "25/24 [==============================] - 65s 3s/step - loss: 0.1671 - accuracy: 0.9461\n",
      "Epoch 7/10\n",
      "25/24 [==============================] - 65s 3s/step - loss: 0.1775 - accuracy: 0.9396\n",
      "Epoch 8/10\n",
      "25/24 [==============================] - 65s 3s/step - loss: 0.1838 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "25/24 [==============================] - 63s 3s/step - loss: 0.1820 - accuracy: 0.9389\n",
      "Epoch 10/10\n",
      "25/24 [==============================] - 62s 2s/step - loss: 0.1737 - accuracy: 0.9429\n"
     ]
    }
   ],
   "source": [
    "img_rows , img_cols = input_dim,input_dim\n",
    "num_classes = len(colors)+1\n",
    "batch_size = 256\n",
    "nb_epoch = 10\n",
    "\n",
    "# # initialise model\n",
    "# model = color_net(num_classes)\n",
    "\n",
    "filepath = 'color_weights.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "train_datagen = ImageDataGenerator( \n",
    "    zca_whitening=True,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "#         rotation_range=45,\n",
    "        vertical_flip=True,\n",
    "        validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(        \n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.3)\n",
    "\n",
    "# training_set = train_datagen.flow_from_directory(\n",
    "#             'train/',\n",
    "#             target_size=(img_rows, img_cols),\n",
    "#             batch_size=batch_size,\n",
    "#             class_mode='categorical')\n",
    "# test_set = test_datagen.flow_from_directory(\n",
    "#             'test/',\n",
    "#             target_size=(img_rows, img_cols),\n",
    "#             batch_size=batch_size,\n",
    "#             class_mode='categorical')\n",
    "# training_set = train_datagen.flow_from_dataframe(X_train,\n",
    "#             target_size=(img_rows, img_cols),\n",
    "#             batch_size=batch_size,\n",
    "#             class_mode='categorical')\n",
    "# training_set = train_datagen.(X_test,\n",
    "#             target_size=(img_rows, img_cols),\n",
    "#             batch_size=batch_size,\n",
    "#             class_mode='categorical')\n",
    "\n",
    "\n",
    "# model.fit_generator(\n",
    "#         training_set,\n",
    "#         steps_per_epoch=12000,\n",
    "#         epochs=nb_epoch,\n",
    "#         validation_data=test_set,\n",
    "#         validation_steps=3000,\n",
    "#         callbacks=callbacks_list)\n",
    "with tf.device('/device:GPU:0'):\n",
    "#     for i in range(10):\n",
    "#     model.fit(X , categorical_labels , batch_size=batch_size,epochs = nb_epoch , validation_split=0.1)\n",
    "    model.fit(train_datagen.flow(X , categorical_labels , batch_size), steps_per_epoch=len(X) / batch_size, epochs=nb_epoch)\n",
    "#     model.fit(advX , to_categorical(advY, num_classes=13),batch_size=batch_size,epochs = 1)\n",
    "# model.save('color_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 10s 407ms/step - loss: 0.0977 - accuracy: 0.9686\n",
      "Test score: 0.09769605845212936\n",
      "Test accuracy: 0.9685847163200378\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X , categorical_labels ,\n",
    "                            batch_size=batch_size)\n",
    "model.save('color_model.h5')\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2673, 12)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = clf.predict_proba(Xtf)\n",
    "pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 6.63596730e-04, 1.17566198e-02, 5.74800747e-04,\n",
       "       2.37803003e-04, 1.20431150e-04, 3.80468230e-02, 2.22868838e-02,\n",
       "       2.07084426e-01, 4.34944910e-03, 6.84231341e-01, 1.24883155e-02,\n",
       "       1.81595106e-02])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred3=np.concatenate((np.zeros((2673,1)) , pred2) , axis=1)\n",
    "pred3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 6.63596730e-04, 1.17566198e-02, ...,\n",
       "        6.84231341e-01, 1.24883155e-02, 1.81595106e-02],\n",
       "       [0.00000000e+00, 9.74664763e-02, 3.61413584e-01, ...,\n",
       "        1.79332862e-04, 1.27340282e-09, 2.57023526e-05],\n",
       "       [0.00000000e+00, 1.24218124e-06, 2.62649591e-14, ...,\n",
       "        3.70154552e-04, 1.12010824e-02, 1.71457825e-16],\n",
       "       ...,\n",
       "       [0.00000000e+00, 5.96794073e-03, 4.57123850e-02, ...,\n",
       "        7.01172528e-02, 1.26265795e-01, 1.05115168e-01],\n",
       "       [0.00000000e+00, 2.47453554e-03, 1.61118447e-02, ...,\n",
       "        7.62951164e-02, 5.84689033e-01, 1.51730610e-02],\n",
       "       [0.00000000e+00, 1.09937860e-03, 6.76537304e-03, ...,\n",
       "        6.66520706e-03, 5.28005955e-01, 9.98602088e-02]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 0.88*pred + 0.12*pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.apply_along_axis(np.argmax ,1, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  2, 11, ...,  7,  7, 11], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>color_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000004.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000033.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000678.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001233.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000001547.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  color_id\n",
       "0  1000000004.jpg        10\n",
       "1  1000000033.jpg         2\n",
       "2  1000000678.jpg        11\n",
       "3  1000001233.jpg         2\n",
       "4  1000001547.jpg        11"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.DataFrame.from_dict({'file_name' : ids , 'color_id' : pred})\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>color_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>117159660.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>117075364.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>115254638.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>117216927.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>117224412.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>105344084.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>115260418.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>117152272.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>117093136.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>117117574.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name  color_id\n",
       "2306  117159660.jpg         3\n",
       "1852  117075364.jpg         5\n",
       "926   115254638.jpg         9\n",
       "2504  117216927.jpg        11\n",
       "2547  117224412.jpg         2\n",
       "211   105344084.jpg         8\n",
       "954   115260418.jpg         5\n",
       "2290  117152272.jpg        12\n",
       "1951  117093136.jpg         1\n",
       "2140  117117574.jpg         5"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.sort_values('file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pink': 1,\n",
       " 'purple': 2,\n",
       " 'yellow': 3,\n",
       " 'orange': 4,\n",
       " 'white': 5,\n",
       " 'silver': 6,\n",
       " 'grey': 7,\n",
       " 'black': 8,\n",
       " 'red': 9,\n",
       " 'brown': 10,\n",
       " 'green': 11,\n",
       " 'blue': 12}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv('data/vision/ans2.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
